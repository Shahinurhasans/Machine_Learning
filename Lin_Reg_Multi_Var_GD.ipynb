{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ff489da-e9b9-4803-9f6b-196694342537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math,copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "387c621a-7694-4b17-a3f1-5753a210b5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array([[2,2,1],[3,1,5],[4,3,2]])\n",
    "Y=np.array([21,24,30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d10cade7-b48e-46fb-bb21-49881cf5aae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost 196.0525\n",
      "Iteration  100: Cost   1.4427\n",
      "Iteration  200: Cost   1.2045\n",
      "Iteration  300: Cost   1.0295\n",
      "Iteration  400: Cost   0.8801\n",
      "Iteration  500: Cost   0.7523\n",
      "Iteration  600: Cost   0.6431\n",
      "Iteration  700: Cost   0.5497\n",
      "Iteration  800: Cost   0.4699\n",
      "Iteration  900: Cost   0.4017\n",
      "Iteration 1000: Cost   0.3434\n",
      "Iteration 1100: Cost   0.2935\n",
      "Iteration 1200: Cost   0.2509\n",
      "Iteration 1300: Cost   0.2145\n",
      "Iteration 1400: Cost   0.1833\n",
      "Iteration 1500: Cost   0.1567\n",
      "Iteration 1600: Cost   0.1340\n",
      "Iteration 1700: Cost   0.1145\n",
      "Iteration 1800: Cost   0.0979\n",
      "Iteration 1900: Cost   0.0837\n",
      "Iteration 2000: Cost   0.0715\n",
      "Iteration 2100: Cost   0.0611\n",
      "Iteration 2200: Cost   0.0523\n",
      "Iteration 2300: Cost   0.0447\n",
      "Iteration 2400: Cost   0.0382\n",
      "Iteration 2500: Cost   0.0326\n",
      "Iteration 2600: Cost   0.0279\n",
      "Iteration 2700: Cost   0.0239\n",
      "Iteration 2800: Cost   0.0204\n",
      "Iteration 2900: Cost   0.0174\n",
      "Iteration 3000: Cost   0.0149\n",
      "Iteration 3100: Cost   0.0127\n",
      "Iteration 3200: Cost   0.0109\n",
      "Iteration 3300: Cost   0.0093\n",
      "Iteration 3400: Cost   0.0080\n",
      "Iteration 3500: Cost   0.0068\n",
      "Iteration 3600: Cost   0.0058\n",
      "Iteration 3700: Cost   0.0050\n",
      "Iteration 3800: Cost   0.0042\n",
      "Iteration 3900: Cost   0.0036\n",
      "Iteration 4000: Cost   0.0031\n",
      "Iteration 4100: Cost   0.0027\n",
      "Iteration 4200: Cost   0.0023\n",
      "Iteration 4300: Cost   0.0019\n",
      "Iteration 4400: Cost   0.0017\n",
      "Iteration 4500: Cost   0.0014\n",
      "Iteration 4600: Cost   0.0012\n",
      "Iteration 4700: Cost   0.0010\n",
      "Iteration 4800: Cost   0.0009\n",
      "Iteration 4900: Cost   0.0008\n",
      "Iteration 5000: Cost   0.0006\n",
      "Iteration 5100: Cost   0.0006\n",
      "Iteration 5200: Cost   0.0005\n",
      "Iteration 5300: Cost   0.0004\n",
      "Iteration 5400: Cost   0.0003\n",
      "Iteration 5500: Cost   0.0003\n",
      "Iteration 5600: Cost   0.0003\n",
      "Iteration 5700: Cost   0.0002\n",
      "Iteration 5800: Cost   0.0002\n",
      "Iteration 5900: Cost   0.0002\n",
      "Iteration 6000: Cost   0.0001\n",
      "Iteration 6100: Cost   0.0001\n",
      "Iteration 6200: Cost   0.0001\n",
      "Iteration 6300: Cost   0.0001\n",
      "Iteration 6400: Cost   0.0001\n",
      "Iteration 6500: Cost   0.0001\n",
      "Iteration 6600: Cost   0.0001\n",
      "Iteration 6700: Cost   0.0000\n",
      "Iteration 6800: Cost   0.0000\n",
      "Iteration 6900: Cost   0.0000\n",
      "Iteration 7000: Cost   0.0000\n",
      "Iteration 7100: Cost   0.0000\n",
      "Iteration 7200: Cost   0.0000\n",
      "Iteration 7300: Cost   0.0000\n",
      "Iteration 7400: Cost   0.0000\n",
      "Iteration 7500: Cost   0.0000\n",
      "Iteration 7600: Cost   0.0000\n",
      "Iteration 7700: Cost   0.0000\n",
      "Iteration 7800: Cost   0.0000\n",
      "Iteration 7900: Cost   0.0000\n",
      "Iteration 8000: Cost   0.0000\n",
      "Iteration 8100: Cost   0.0000\n",
      "Iteration 8200: Cost   0.0000\n",
      "Iteration 8300: Cost   0.0000\n",
      "Iteration 8400: Cost   0.0000\n",
      "Iteration 8500: Cost   0.0000\n",
      "Iteration 8600: Cost   0.0000\n",
      "Iteration 8700: Cost   0.0000\n",
      "Iteration 8800: Cost   0.0000\n",
      "Iteration 8900: Cost   0.0000\n",
      "Iteration 9000: Cost   0.0000\n",
      "Iteration 9100: Cost   0.0000\n",
      "Iteration 9200: Cost   0.0000\n",
      "Iteration 9300: Cost   0.0000\n",
      "Iteration 9400: Cost   0.0000\n",
      "Iteration 9500: Cost   0.0000\n",
      "Iteration 9600: Cost   0.0000\n",
      "Iteration 9700: Cost   0.0000\n",
      "Iteration 9800: Cost   0.0000\n",
      "Iteration 9900: Cost   0.0000\n",
      "\n",
      "Final model: price = 6.23 + 0.59*area + 5.77*room + 2.05*fan\n",
      "\n",
      "Predictions vs Actual:\n",
      "Prediction: 21.00, Actual: 21\n",
      "Prediction: 24.00, Actual: 24\n",
      "Prediction: 30.00, Actual: 30\n"
     ]
    }
   ],
   "source": [
    "def compute_cost(X, y, w, b): \n",
    "    m = X.shape[0]\n",
    "    cost = 0.0\n",
    "    for i in range(m):                                \n",
    "        f_wb_i = np.dot(X[i], w) + b           \n",
    "        cost += (f_wb_i - y[i])**2       \n",
    "    return cost / (2 * m)\n",
    "\n",
    "def compute_gradient(X, y, w, b): \n",
    "    m, n = X.shape          \n",
    "    dj_dw = np.zeros((n,))\n",
    "    dj_db = 0.\n",
    "    for i in range(m):                             \n",
    "        err = (np.dot(X[i], w) + b) - y[i]   \n",
    "        for j in range(n):                         \n",
    "            dj_dw[j] += err * X[i, j]    \n",
    "        dj_db += err                        \n",
    "    dj_dw /= m                                \n",
    "    dj_db /= m                                \n",
    "        \n",
    "    return dj_db, dj_dw\n",
    "    \n",
    "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters): \n",
    "    J_history = []\n",
    "    w = copy.deepcopy(w_in)\n",
    "    b = b_in\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        dj_db, dj_dw = gradient_function(X, y, w, b)\n",
    "\n",
    "        w -= alpha * dj_dw\n",
    "        b -= alpha * dj_db\n",
    "\n",
    "        if i < 100000:\n",
    "            J_history.append(cost_function(X, y, w, b))\n",
    "\n",
    "        if i % math.ceil(num_iters / 100) == 0:\n",
    "            print(f\"Iteration {i:4d}: Cost {J_history[-1]:8.4f}\")\n",
    "        \n",
    "    return w, b, J_history\n",
    "# Initialize\n",
    "w_init = np.zeros(X.shape[1])\n",
    "b_init = 0.\n",
    "iterations = 10000\n",
    "alpha = 1e-2  \n",
    "\n",
    "w_final, b_final, J_hist = gradient_descent(X, Y, w_init, b_init,\n",
    "                                            compute_cost, compute_gradient,\n",
    "                                            alpha, iterations)\n",
    "\n",
    "# Final results\n",
    "print(f\"\\nFinal model: price = {b_final:.2f} + {w_final[0]:.2f}*area + {w_final[1]:.2f}*room + {w_final[2]:.2f}*fan\")\n",
    "\n",
    "print(\"\\nPredictions vs Actual:\")\n",
    "for i in range(X.shape[0]):\n",
    "    pred = np.dot(X[i], w_final) + b_final\n",
    "    print(f\"Prediction: {pred:.2f}, Actual: {Y[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d68fc05-5172-4c3c-8d11-f36648aed450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2029f22d-e21a-4373-9b13-283d6899be76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
